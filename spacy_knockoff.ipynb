{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import art.config\n",
    "import os\n",
    "art.config.ART_NUMPY_DTYPE = 'str' # override dtype to str instead of float\n",
    "\n",
    "from art.estimators.classification import BlackBoxClassifier\n",
    "from art.attacks.extraction import KnockoffNets\n",
    "from spacy_clf import SpacyClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating use case fake-news\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Skipping already performed baseline eval\n",
      "Evaluating random strategy..\n",
      "Already evaluated 1 queries - skipping\n",
      "Already evaluated 10 queries - skipping\n",
      "Already evaluated 100 queries - skipping\n",
      "Already evaluated 250 queries - skipping\n",
      "Already evaluated 500 queries - skipping\n",
      "Already evaluated 1000 queries - skipping\n",
      "Already evaluated 2500 queries - skipping\n",
      "Already evaluated 5000 queries - skipping\n",
      "Already evaluated 10000 queries - skipping\n",
      "Already evaluated 25000 queries - skipping\n",
      "Already evaluated 50000 queries - skipping\n",
      "Evaluating use case spam\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (1.0, 1.0, 1.0)\n",
      "Test (1.0, 1.0, 1.0)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n",
      "Evaluating on train/test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (0.43475, 0.5, 0.46509761968440766)\n",
      "Test (0.43262730959891843, 0.5, 0.4638801642908916)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.7705829326923077, 0.7222090028399639, 0.7427596813843153)\n",
      "Test (0.7550771734355657, 0.7225260416666667, 0.737028613175594)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.824468401120996, 0.9211485880598134, 0.8625691925940064)\n",
      "Test (0.8203386351104891, 0.9111264980490523, 0.8563237940533261)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9334805322066468, 0.9502819033266575, 0.9416482426395741)\n",
      "Test (0.9248309774164702, 0.9325969377090301, 0.9286618566481574)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9713439709724105, 0.9527759601127173, 0.9617956064947468)\n",
      "Test (0.9577637660588856, 0.9381958960423634, 0.9476712651809929)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9848791868257851, 0.9528729022492779, 0.9681092667637057)\n",
      "Test (0.976649886776469, 0.9459469934503901, 0.9605687470301609)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9913878117559025, 0.9687736158755968, 0.9797061449793003)\n",
      "Test (0.9892439650518383, 0.9641016931438127, 0.9761999249208988)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (1.0, 1.0, 1.0)\n",
      "Test (1.0, 1.0, 1.0)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating use case hate-speech\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9458588640586049, 0.8421651442354076, 0.8805754970997137)\n",
      "Test (0.9677875067121114, 0.8649890705905002, 0.9041339887842775)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.26016666666666666, 0.3333333333333333, 0.2922400074885332)\n",
      "Test (0.2578212007694644, 0.3333333333333333, 0.29075443153598035)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.26016666666666666, 0.3333333333333333, 0.2922400074885332)\n",
      "Test (0.5911675863581903, 0.33343256921702885, 0.2909611439155856)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.43472906243102655, 0.38863532532279454, 0.38866953875678595)\n",
      "Test (0.4299493066568876, 0.3887471210211381, 0.38715401070299554)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.5680329887482835, 0.39564270483823044, 0.40452158357423573)\n",
      "Test (0.6227764740614262, 0.40045802936842917, 0.41348201835660187)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.6160290512700151, 0.44400881979028567, 0.46255668771286146)\n",
      "Test (0.6211596801915892, 0.44710117573173797, 0.4700867767321409)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.5647818704216521, 0.47709719097638476, 0.5001741475698641)\n",
      "Test (0.6132682225423359, 0.48945642629009334, 0.5204209647037694)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.6541522073927758, 0.5887404581930974, 0.6153459079734944)\n",
      "Test (0.6538454042221414, 0.5864372277154172, 0.6136585239412199)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.7517288851776002, 0.6471909633391575, 0.6702630278991609)\n",
      "Test (0.8028976590133444, 0.646177110277411, 0.6846763942681521)\n",
      "Saving classifier\n",
      "Training with 10000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.8153154796446601, 0.7500156951355988, 0.7747775107022458)\n",
      "Test (0.8307101967971405, 0.7719082738524067, 0.7963367861633851)\n",
      "Saving classifier\n",
      "Training with 25000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9423850845752373, 0.8384700937189379, 0.8762282474879911)\n",
      "Test (0.9610299740412785, 0.8569000737982778, 0.8957589016098919)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n"
     ]
    }
   ],
   "source": [
    "target_class_dict = {\n",
    "    'fake-news': ['False', 'True'],\n",
    "    'spam': ['spam', 'ham'],\n",
    "    'hate-speech': ['Offensive_Language', 'Hate_Speech', 'Neither']    \n",
    "}\n",
    "\n",
    "def eval_clf(art_clf, texts, labels, use_case):\n",
    "    preds = art_clf.predict(texts)\n",
    "    if use_case == 'fake_news':\n",
    "        # boolean indicators\n",
    "        return precision_recall_fscore_support(labels.astype(int), np.argmax(preds, axis=1), average='macro')\n",
    "    \n",
    "    # string indicators\n",
    "    target_labels = target_class_dict.get(use_case)\n",
    "    pred_labels = [target_labels[x] for x in np.argmax(preds,axis=1)]\n",
    "    return precision_recall_fscore_support(labels, pred_labels, average='macro')\n",
    "\n",
    "for use_case in ['fake-news', 'spam', 'hate-speech']:\n",
    "    print(\"Evaluating use case\", use_case)\n",
    "    \n",
    "    print(\"Loading data..\")\n",
    "    df = pd.read_csv(f'res/{use_case}/train.csv')\n",
    "    texts = df['text'].to_numpy()\n",
    "    labels = df['target'].to_numpy()\n",
    "    \n",
    "    df_train_eval = df.sample(n=2000, random_state=212132)\n",
    "    train_eval_texts = df_train_eval['text'].to_numpy()\n",
    "    train_labels = df_train_eval['target'].to_numpy()\n",
    "    \n",
    "    df_test = pd.read_csv(f'res/{use_case}/test.csv')\n",
    "    test_eval_texts = df['text'].to_numpy()\n",
    "    test_eval_labels = df['target'].to_numpy()\n",
    "    \n",
    "    print(\"Loading Victim model..\")\n",
    "    blackbox_classifier = SpacyClassifier(model = spacy.load(f'blackbox-models/{use_case}/'))\n",
    "    \n",
    "    if os.path.exists(f'eval/{use_case}/spacy_random_res.csv'):\n",
    "        df_stats = pd.read_csv(f'eval/{use_case}/spacy_random_res.csv', index_col=0)\n",
    "        print(\"Skipping already performed baseline eval\")\n",
    "    else:\n",
    "        print(\"Calculating performance baselines with blackbox..\")\n",
    "        p,r,f,_ = eval_clf(blackbox_classifier, train_eval_texts, train_labels, use_case)\n",
    "        df_stats = pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_r'])\n",
    "        print(\"Train\", (p,r,f))\n",
    "        p,r,f,_ = eval_clf(blackbox_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "        df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_e']))\n",
    "        print(\"Test\", (p,r,f))\n",
    "\n",
    "    \n",
    "    print(\"Evaluating random strategy..\")\n",
    "    for nb_stolen in [1,10,100,250,500,1000,2500,5000,10000,25000,50000]:\n",
    "        if f'q_{nb_stolen}_e' in df_stats.index.tolist():\n",
    "            print(f\"Already evaluated {nb_stolen} queries - skipping\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Training with {nb_stolen} queries to black box\")\n",
    "        knockoff = KnockoffNets(classifier = blackbox_classifier, batch_size_fit=32, batch_size_query=32, nb_stolen=nb_stolen, sampling_strategy='random')\n",
    "        np.random.seed(23435432)\n",
    "        thieved_classifier = SpacyClassifier(model = spacy.load(\"en_core_web_sm\"), target_classes=target_class_dict.get(use_case))\n",
    "        knockoff.extract(x = texts, thieved_classifier=thieved_classifier)\n",
    "        \n",
    "        print(\"Evaluating on train/test set\")\n",
    "        p,r,f,_ = eval_clf(thieved_classifier, train_eval_texts, train_labels, use_case)\n",
    "        df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_r']))\n",
    "        print(\"Train\", (p,r,f))\n",
    "        p,r,f,_ = eval_clf(thieved_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "        df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_e']))\n",
    "        print(\"Test\", (p,r,f))\n",
    "        \n",
    "        print(\"Saving classifier\")\n",
    "        thieved_classifier.save(f'stolen-models-spacy/{use_case}/{nb_stolen}_queries/')\n",
    "        df_stats.to_csv(f'eval/{use_case}/spacy_random_res.csv')\n",
    "        \n",
    "        if nb_stolen > texts.shape[0]:\n",
    "            print(\"Evaluated max query size - Stopping\")\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
