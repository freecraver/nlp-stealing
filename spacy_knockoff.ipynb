{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import art.config\n",
    "import os\n",
    "art.config.ART_NUMPY_DTYPE = 'str' # override dtype to str instead of float\n",
    "\n",
    "from art.estimators.classification import BlackBoxClassifier\n",
    "from art.attacks.extraction import KnockoffNets\n",
    "from spacy_clf import SpacyClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating setting random\n",
      "Evaluating use case fake-news\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Skipping already performed baseline eval\n",
      "Evaluating random strategy..\n",
      "Already evaluated 1 queries - skipping\n",
      "Already evaluated 10 queries - skipping\n",
      "Already evaluated 100 queries - skipping\n",
      "Already evaluated 250 queries - skipping\n",
      "Already evaluated 500 queries - skipping\n",
      "Already evaluated 1000 queries - skipping\n",
      "Already evaluated 2500 queries - skipping\n",
      "Already evaluated 5000 queries - skipping\n",
      "Already evaluated 10000 queries - skipping\n",
      "Already evaluated 25000 queries - skipping\n",
      "Already evaluated 50000 queries - skipping\n",
      "Evaluating use case spam\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Skipping already performed baseline eval\n",
      "Evaluating random strategy..\n",
      "Already evaluated 1 queries - skipping\n",
      "Already evaluated 10 queries - skipping\n",
      "Already evaluated 100 queries - skipping\n",
      "Already evaluated 250 queries - skipping\n",
      "Already evaluated 500 queries - skipping\n",
      "Already evaluated 1000 queries - skipping\n",
      "Already evaluated 2500 queries - skipping\n",
      "Already evaluated 5000 queries - skipping\n",
      "Evaluating use case hate-speech\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Skipping already performed baseline eval\n",
      "Evaluating random strategy..\n",
      "Already evaluated 1 queries - skipping\n",
      "Already evaluated 10 queries - skipping\n",
      "Already evaluated 100 queries - skipping\n",
      "Already evaluated 250 queries - skipping\n",
      "Already evaluated 500 queries - skipping\n",
      "Already evaluated 1000 queries - skipping\n",
      "Already evaluated 2500 queries - skipping\n",
      "Already evaluated 5000 queries - skipping\n",
      "Already evaluated 10000 queries - skipping\n",
      "Already evaluated 25000 queries - skipping\n",
      "Evaluating setting adaptive\n",
      "Evaluating use case fake-news\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Skipping already performed baseline eval\n",
      "Evaluating random strategy..\n",
      "Already evaluated 1 queries - skipping\n",
      "Already evaluated 10 queries - skipping\n",
      "Already evaluated 100 queries - skipping\n",
      "Already evaluated 250 queries - skipping\n",
      "Already evaluated 500 queries - skipping\n",
      "Already evaluated 1000 queries - skipping\n",
      "Already evaluated 2500 queries - skipping\n",
      "Already evaluated 5000 queries - skipping\n",
      "Already evaluated 10000 queries - skipping\n",
      "Already evaluated 25000 queries - skipping\n",
      "Already evaluated 50000 queries - skipping\n",
      "Evaluating use case spam\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (1.0, 1.0, 1.0)\n",
      "Test (1.0, 1.0, 1.0)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (0.43475, 0.5, 0.46509761968440766)\n",
      "Test (0.43262730959891843, 0.5, 0.4638801642908916)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.6603571428571429, 0.7967751316980958, 0.6780971769122415)\n",
      "Test (0.6657253686301179, 0.7988368345875139, 0.6844131937487479)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.7951034765130649, 0.9192262695564236, 0.8385769521254409)\n",
      "Test (0.7966642759176072, 0.9106884057971014, 0.8376019883193484)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.8098406267009151, 0.9377146772597984, 0.8551876315756128)\n",
      "Test (0.7982212128521733, 0.9280209204292085, 0.8425549853648093)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 500/500 [00:40<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9046568983026257, 0.9609102866623043, 0.9300283385228981)\n",
      "Test (0.891805863833502, 0.9593053232998885, 0.9213893774995324)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [01:19<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.8666833250623817, 0.9623412847917616, 0.9058047118036893)\n",
      "Test (0.8723321792155444, 0.9612314485785953, 0.9092079359115754)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 2500/2500 [03:30<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9379194630872483, 0.9893617021276595, 0.961528843749399)\n",
      "Test (0.9332188732631894, 0.9832645275919732, 0.9561808846761454)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets:  72%|████████████████████████████████████████████▍                 | 3587/5000 [05:15<02:37,  8.96it/s]"
     ]
    }
   ],
   "source": [
    "target_class_dict = {\n",
    "    'fake-news': ['False', 'True'],\n",
    "    'spam': ['spam', 'ham'],\n",
    "    'hate-speech': ['Offensive_Language', 'Hate_Speech', 'Neither']    \n",
    "}\n",
    "\n",
    "def eval_clf(art_clf, texts, labels, use_case):\n",
    "    preds = art_clf.predict(texts)\n",
    "    if use_case == 'fake-news':\n",
    "        # boolean indicators\n",
    "        return precision_recall_fscore_support(labels.astype(int), np.argmax(preds, axis=1), average='macro')\n",
    "    \n",
    "    # string indicators\n",
    "    target_labels = target_class_dict.get(use_case)\n",
    "    pred_labels = [target_labels[x] for x in np.argmax(preds,axis=1)]\n",
    "    return precision_recall_fscore_support(labels, pred_labels, average='macro')\n",
    "\n",
    "for setting in ['random', 'adaptive']:\n",
    "    print(\"Evaluating setting\", setting)\n",
    "    for use_case in ['fake-news', 'spam', 'hate-speech']:\n",
    "        print(\"Evaluating use case\", use_case)\n",
    "\n",
    "        print(\"Loading data..\")\n",
    "        df = pd.read_csv(f'res/{use_case}/train.csv')\n",
    "        texts = df['text'].to_numpy()\n",
    "        labels = df['target'].to_numpy()\n",
    "        action_ids = np.array([target_class_dict.get(use_case).index(str(x)) for x in labels]) # required for knockoff action sampling\n",
    "\n",
    "        df_train_eval = df.sample(n=2000, random_state=212132)\n",
    "        train_eval_texts = df_train_eval['text'].to_numpy()\n",
    "        train_labels = df_train_eval['target'].to_numpy()\n",
    "\n",
    "        df_test = pd.read_csv(f'res/{use_case}/test.csv')\n",
    "        test_eval_texts = df['text'].to_numpy()\n",
    "        test_eval_labels = df['target'].to_numpy()\n",
    "\n",
    "        print(\"Loading Victim model..\")\n",
    "        blackbox_classifier = SpacyClassifier(model = spacy.load(f'blackbox-models/{use_case}/'))\n",
    "\n",
    "        if os.path.exists(f'eval/{use_case}/spacy_{setting}_res.csv'):\n",
    "            df_stats = pd.read_csv(f'eval/{use_case}/spacy_{setting}_res.csv', index_col=0)\n",
    "            print(\"Skipping already performed baseline eval\")\n",
    "        else:\n",
    "            print(\"Calculating performance baselines with blackbox..\")\n",
    "            p,r,f,_ = eval_clf(blackbox_classifier, train_eval_texts, train_labels, use_case)\n",
    "            df_stats = pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_r'])\n",
    "            print(\"Train\", (p,r,f))\n",
    "            p,r,f,_ = eval_clf(blackbox_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_e']))\n",
    "            print(\"Test\", (p,r,f))\n",
    "\n",
    "\n",
    "        print(\"Evaluating random strategy..\")\n",
    "        for nb_stolen in [1,10,100,250,500,1000,2500,5000,10000,25000,50000]:\n",
    "            if f'q_{nb_stolen}_e' in df_stats.index.tolist():\n",
    "                print(f\"Already evaluated {nb_stolen} queries - skipping\")\n",
    "                if nb_stolen > texts.shape[0]:\n",
    "                    # fully evaluated\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            print(f\"Training with {nb_stolen} queries to black box\")\n",
    "            knockoff = KnockoffNets(classifier = blackbox_classifier, batch_size_fit=32, batch_size_query=32, nb_stolen=nb_stolen, sampling_strategy=setting)\n",
    "            np.random.seed(23435432)\n",
    "            thieved_classifier = SpacyClassifier(model = spacy.load(\"en_core_web_sm\"), target_classes=target_class_dict.get(use_case))\n",
    "            knockoff.extract(x = texts, y=action_ids, thieved_classifier=thieved_classifier)\n",
    "\n",
    "            print(\"Evaluating on train/test set\")\n",
    "            p,r,f,_ = eval_clf(thieved_classifier, train_eval_texts, train_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_r']))\n",
    "            print(\"Train\", (p,r,f))\n",
    "            p,r,f,_ = eval_clf(thieved_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_e']))\n",
    "            print(\"Test\", (p,r,f))\n",
    "\n",
    "            print(\"Saving classifier\")\n",
    "            thieved_classifier.save(f'stolen-models-spacy/{use_case}/{setting}_{nb_stolen}_queries/')\n",
    "            df_stats.to_csv(f'eval/{use_case}/spacy_{setting}_res.csv')\n",
    "\n",
    "            if nb_stolen > texts.shape[0]:\n",
    "                print(\"Evaluated max query size - Stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
