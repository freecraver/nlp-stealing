{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import spacy\n",
    "import art.config\n",
    "import os\n",
    "art.config.ART_NUMPY_DTYPE = 'str' # override dtype to str instead of float\n",
    "\n",
    "from art.estimators.classification import BlackBoxClassifier\n",
    "from art.attacks.extraction import KnockoffNets\n",
    "from wex_clf import OnewexClassifier\n",
    "from spacy_clf import SpacyClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# hide ssl errors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating setting random\n",
      "Evaluating use case fake-news\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9500277759623554, 0.9411477352809277, 0.9425551470588236)\n",
      "Test (0.9527223973982473, 0.9435230777683176, 0.9453816334906979)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.242, 0.5, 0.32614555256064687)\n",
      "Test (0.23937385103893932, 0.5, 0.3237521190431343)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9729604022627278, 0.9707820808507912, 0.9714181917192485)\n",
      "Test (0.9660830098556379, 0.9632402614229467, 0.9641369804726445)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9372881355932203, 0.9235537190082644, 0.9251590875072313)\n",
      "Test (0.941743059611477, 0.9290450899766804, 0.9311701269753341)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9680602531293154, 0.9644876353385867, 0.9653647058823529)\n",
      "Test (0.9675419935559388, 0.9630910741999863, 0.9643168608812689)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.977218370013064, 0.9753667755781921, 0.9759374132117637)\n",
      "Test (0.9778586870550636, 0.9756086647187983, 0.9763741025267019)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9813410096863173, 0.9807242616439233, 0.9809695512820513)\n",
      "Test (0.9810618225714385, 0.9803458432603911, 0.9806491902781602)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9786749715394996, 0.9768843295534627, 0.9774424726659163)\n",
      "Test (0.977853251484176, 0.9757267721770738, 0.9764603169144862)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.95643744206094, 0.9499927926196425, 0.9512069366633342)\n",
      "Test (0.9565302511670273, 0.9488649111576983, 0.9505547811082247)\n",
      "Saving classifier\n",
      "Training with 10000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9669683257918552, 0.962293388429752, 0.9633279254582314)\n",
      "Test (0.964540672998272, 0.9590488052474606, 0.9604481013143786)\n",
      "Saving classifier\n",
      "Training with 25000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.950261780104712, 0.9411157024793388, 0.9425448981381523)\n",
      "Test (0.954190468220852, 0.9454744840759062, 0.9472843717142815)\n",
      "Saving classifier\n",
      "Training with 50000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9496335452897162, 0.9406312063553078, 0.942046090492258)\n",
      "Test (0.9526912743058633, 0.9434625255449738, 0.9453242371101012)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating use case spam\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9915033512240972, 0.9931027873067492, 0.9923012244902447)\n",
      "Test (0.9833797116114344, 0.9867866847826088, 0.9850745442858422)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.43475, 0.5, 0.46509761968440766)\n",
      "Test (0.43262730959891843, 0.5, 0.4638801642908916)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.8185796423917571, 0.708996230272826, 0.7475333279138917)\n",
      "Test (0.7931964508691973, 0.7029725822185061, 0.7359021299495075)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9175853903609548, 0.8928106389588415, 0.9046529366895499)\n",
      "Test (0.8960815295660978, 0.8870902139074693, 0.8915091264667536)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9537321620960653, 0.9537321620960653, 0.9537321620960653)\n",
      "Test (0.9366623241271496, 0.9378945443143812, 0.9372771585533064)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.974154187983121, 0.9476038768041704, 0.9603393815776428)\n",
      "Test (0.9622256164909809, 0.93646878483835, 0.9488164832077635)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9752211939740087, 0.9533510032409519, 0.9639220355187561)\n",
      "Test (0.9648301306547294, 0.9449601971850613, 0.9545826075155787)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.988660402587383, 0.9758614079964043, 0.9821409038042107)\n",
      "Test (0.9766546658059765, 0.9678712026198439, 0.9722040400979296)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.9915033512240972, 0.9931027873067492, 0.9923012244902447)\n",
      "Test (0.9833797116114344, 0.9867866847826088, 0.9850745442858422)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating use case hate-speech\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9374741762302738, 0.8616457303559427, 0.8960040468886737)\n",
      "Test (0.923283677313214, 0.8675451469239016, 0.8926359387667132)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.26016666666666666, 0.3333333333333333, 0.2922400074885332)\n",
      "Test (0.2578212007694644, 0.3333333333333333, 0.29075443153598035)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.26016666666666666, 0.3333333333333333, 0.2922400074885332)\n",
      "Test (0.4244970973403537, 0.3334107527805256, 0.2909503542735684)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.5272872030860231, 0.36463148995720673, 0.3563301688480311)\n",
      "Test (0.5688058829671673, 0.36649891902786075, 0.35814330573064374)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.5808527058527059, 0.37710215577051526, 0.377105918570817)\n",
      "Test (0.575221760135866, 0.3860499817981646, 0.3899913207742797)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.54936592457043, 0.44717047797238507, 0.46872777229890733)\n",
      "Test (0.5751416451991702, 0.47016155511802743, 0.4906840218969446)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.5712320015725588, 0.4930750812919811, 0.514375876634232)\n",
      "Test (0.6283695062660635, 0.511248870471332, 0.5425556325089221)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.6766937191249118, 0.5429763873720238, 0.585011866923899)\n",
      "Test (0.6784859522380438, 0.5478650238029786, 0.5897090845916991)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.737898108771403, 0.626915401361673, 0.6645662362352883)\n",
      "Test (0.7151869263483098, 0.6164142761296084, 0.6493672942036771)\n",
      "Saving classifier\n",
      "Training with 10000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.7908788548983882, 0.786615465425657, 0.7884831389337518)\n",
      "Test (0.7525835307108477, 0.7624515034977639, 0.7553827880138914)\n",
      "Saving classifier\n",
      "Training with 25000 queries to black box\n",
      "Evaluating on train/test set\n",
      "Train (0.8935941319994075, 0.8658806463242552, 0.8780146838398286)\n",
      "Test (0.8931787482585117, 0.8671211884151031, 0.877644133893102)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating setting adaptive\n",
      "Evaluating use case fake-news\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9500277759623554, 0.9411477352809277, 0.9425551470588236)\n",
      "Test (0.9527223973982473, 0.9435230777683176, 0.9453816334906979)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.258, 0.5, 0.3403693931398417)\n",
      "Test (0.2606261489610607, 0.5, 0.3426468434158489)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9680602531293154, 0.9644876353385867, 0.9653647058823529)\n",
      "Test (0.9627228015789493, 0.9577193983917589, 0.9590327536141029)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9899361099101696, 0.9900538151066692, 0.9899909918927035)\n",
      "Test (0.9888066578859732, 0.988933903198866, 0.9888677754871757)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 250/250 [00:16<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9854807399207457, 0.984664296239349, 0.9849734932420791)\n",
      "Test (0.984122799157995, 0.9831143983555711, 0.9835210926354738)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 500/500 [00:33<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9832381520071368, 0.982049618809661, 0.9824636954655375)\n",
      "Test (0.9762269390558815, 0.9740697609117053, 0.9748100896842968)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [01:07<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9764249027675551, 0.9743016849253636, 0.9749295771823051)\n",
      "Test (0.9800262980213148, 0.9783418808437698, 0.9789562141133024)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 2500/2500 [02:46<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9676279606603952, 0.9639711064129668, 0.9648605314493224)\n",
      "Test (0.9693040166869937, 0.9653523579173184, 0.9664865716156164)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 5000/5000 [05:50<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9631956912028725, 0.9576446280991735, 0.9587803404341737)\n",
      "Test (0.9611578807242309, 0.954460941394103, 0.9560350662350515)\n",
      "Saving classifier\n",
      "Training with 10000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████| 10000/10000 [12:05<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.968636875431311, 0.9649721314626177, 0.9658645162650559)\n",
      "Test (0.9694761153325442, 0.9654111629337249, 0.9665677318117866)\n",
      "Saving classifier\n",
      "Training with 25000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████| 25000/25000 [31:05<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9513882375967934, 0.9432458837849959, 0.9445997330714412)\n",
      "Test (0.9535450206931626, 0.9446647065118887, 0.9464907885894822)\n",
      "Saving classifier\n",
      "Training with 50000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████| 50000/50000 [5:10:22<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9525884240279086, 0.9447954705618553, 0.9461243656081111)\n",
      "Test (0.9572916374855238, 0.9495856713262748, 0.9512838283540197)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating use case spam\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9915033512240972, 0.9931027873067492, 0.9923012244902447)\n",
      "Test (0.9833797116114344, 0.9867866847826088, 0.9850745442858422)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.43475, 0.5, 0.46509761968440766)\n",
      "Test (0.43262730959891843, 0.5, 0.4638801642908916)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.5896000675624953, 0.6683003619907508, 0.41610361450448186)\n",
      "Test (0.5952746057134355, 0.6784672867892977, 0.43344541724155716)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.7312708585263423, 0.8965054563000271, 0.7697070073741079)\n",
      "Test (0.7393300224592794, 0.9008966520345596, 0.7781977722498394)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 250/250 [00:17<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.8643521590433417, 0.9391621996170786, 0.8963242975971162)\n",
      "Test (0.8689038780109506, 0.9353321836677815, 0.897788456447945)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 500/500 [00:37<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.8732086619860738, 0.9553504348075148, 0.9079367892014802)\n",
      "Test (0.8726828151416266, 0.9522396704292084, 0.9063708945825)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [01:12<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.8948025439025624, 0.9640697190220302, 0.9251737687545882)\n",
      "Test (0.8931738456997631, 0.9588598278985507, 0.9220831962653708)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 2500/2500 [03:04<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9324320294249218, 0.9792081149381222, 0.9540437336541916)\n",
      "Test (0.9210763896013296, 0.9736561106465997, 0.9450193881607771)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 5000/5000 [06:29<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.9804772327737754, 0.9913776579220452, 0.9858400062303971)\n",
      "Test (0.9710091417563662, 0.9855394718506132, 0.9781131894225256)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n",
      "Evaluating use case hate-speech\n",
      "Loading data..\n",
      "Loading Victim model..\n",
      "Calculating performance baselines with blackbox..\n",
      "Train (0.9374741762302738, 0.8616457303559427, 0.8960040468886737)\n",
      "Test (0.923283677313214, 0.8675451469239016, 0.8926359387667132)\n",
      "Evaluating random strategy..\n",
      "Training with 1 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.05616666666666667, 0.3333333333333333, 0.09613464555698188)\n",
      "Test (0.05668050352671189, 0.3333333333333333, 0.09688631217640865)\n",
      "Saving classifier\n",
      "Training with 10 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.3391824827667346, 0.3701050139687017, 0.30586026613287437)\n",
      "Test (0.34553419548098013, 0.3872117543920257, 0.3181799592333833)\n",
      "Saving classifier\n",
      "Training with 100 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.47733333333333333, 0.4603148574036207, 0.367103419853954)\n",
      "Test (0.4780643414358435, 0.4633338477959518, 0.36022778029261643)\n",
      "Saving classifier\n",
      "Training with 250 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 250/250 [00:18<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.5017729601026021, 0.5673053633281943, 0.47420788509902473)\n",
      "Test (0.5038820858323964, 0.5568934029880938, 0.47198564249322156)\n",
      "Saving classifier\n",
      "Training with 500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████████| 500/500 [00:38<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.4852657411828343, 0.605781853133264, 0.4425900368139291)\n",
      "Test (0.48309912882461453, 0.5814402775235095, 0.4359509936761207)\n",
      "Saving classifier\n",
      "Training with 1000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [01:20<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.5311686717057401, 0.6320146151810557, 0.5314784118714974)\n",
      "Test (0.5363532455499446, 0.6303616211061499, 0.5312237542558221)\n",
      "Saving classifier\n",
      "Training with 2500 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 2500/2500 [03:05<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.5482896827665854, 0.6838280254950379, 0.567092082781461)\n",
      "Test (0.5652607603515979, 0.7076671134243527, 0.587162527476886)\n",
      "Saving classifier\n",
      "Training with 5000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|██████████████████████████████████████████████████████████████| 5000/5000 [06:10<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.6253188329334163, 0.768473081416747, 0.6589029759778163)\n",
      "Test (0.6326185910193859, 0.7776450849021709, 0.6654613584695898)\n",
      "Saving classifier\n",
      "Training with 10000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████| 10000/10000 [12:49<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.656919962074937, 0.8100822432560024, 0.6990411566061638)\n",
      "Test (0.6557277579227243, 0.8046115473129808, 0.6957909482798755)\n",
      "Saving classifier\n",
      "Training with 25000 queries to black box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Knock-off nets: 100%|████████████████████████████████████████████████████████████| 25000/25000 [35:30<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on train/test set\n",
      "Train (0.7663632618341222, 0.8270062647973943, 0.7865072713909923)\n",
      "Test (0.7872611221538746, 0.8423629908828364, 0.8063913291636542)\n",
      "Saving classifier\n",
      "Evaluated max query size - Stopping\n"
     ]
    }
   ],
   "source": [
    "target_class_dict = {\n",
    "    'fake-news': ['False', 'True'],\n",
    "    'spam': ['spam', 'ham'],\n",
    "    'hate-speech': ['Offensive_Language', 'Hate_Speech', 'Neither']    \n",
    "}\n",
    "\n",
    "collection_dict = {\n",
    "    'fake-news': 'e54f9c0d-5b66-4c10-0000-01737d592c53',\n",
    "    'spam': 'e54f9c0d-5b66-4c10-0000-01738025f3a2',\n",
    "    'hate-speech': 'e54f9c0d-5b66-4c10-0000-0173802bad98'\n",
    "}\n",
    "\n",
    "def eval_clf(art_clf, texts, labels, use_case):\n",
    "    preds = art_clf.predict(texts)\n",
    "    if use_case == 'fake-news':\n",
    "        # boolean indicators\n",
    "        return precision_recall_fscore_support(labels.astype(int), np.argmax(preds, axis=1), average='macro')\n",
    "    \n",
    "    # string indicators\n",
    "    target_labels = target_class_dict.get(use_case)\n",
    "    pred_labels = [target_labels[x] for x in np.argmax(preds,axis=1)]\n",
    "    return precision_recall_fscore_support(labels, pred_labels, average='macro')\n",
    "\n",
    "session = requests.Session()\n",
    "session.auth = ('admin', 'admin') # dummy credentials\n",
    "\n",
    "for setting in ['random', 'adaptive']:\n",
    "    print(\"Evaluating setting\", setting)\n",
    "    for use_case in ['fake-news', 'spam', 'hate-speech']:\n",
    "        print(\"Evaluating use case\", use_case)\n",
    "\n",
    "        print(\"Loading data..\")\n",
    "        df = pd.read_csv(f'res/{use_case}/train.csv')\n",
    "        texts = df['text'].to_numpy()\n",
    "        labels = df['target'].to_numpy()\n",
    "        action_ids = np.array([target_class_dict.get(use_case).index(str(x)) for x in labels]) # required for knockoff action sampling\n",
    "\n",
    "        df_train_eval = df.sample(n=2000, random_state=212132)\n",
    "        train_eval_texts = df_train_eval['text'].to_numpy()\n",
    "        train_labels = df_train_eval['target'].to_numpy()\n",
    "\n",
    "        df_test = pd.read_csv(f'res/{use_case}/test.csv')\n",
    "        test_eval_texts = df['text'].to_numpy()\n",
    "        test_eval_labels = df['target'].to_numpy()\n",
    "\n",
    "        print(\"Loading Victim model..\")\n",
    "        blackbox_classifier = OnewexClassifier(\n",
    "            prediction_url=f'https://localhost/api/v1/collections/{collection_dict.get(use_case)}/analyze',\n",
    "            target_classes=target_class_dict.get(use_case),\n",
    "            web_session=session\n",
    "        )\n",
    "\n",
    "        if os.path.exists(f'eval/{use_case}/wex_{setting}_res.csv'):\n",
    "            df_stats = pd.read_csv(f'eval/{use_case}/wex_{setting}_res.csv', index_col=0)\n",
    "            print(\"Skipping already performed baseline eval\")\n",
    "        else:\n",
    "            print(\"Calculating performance baselines with blackbox..\")\n",
    "            p,r,f,_ = eval_clf(blackbox_classifier, train_eval_texts, train_labels, use_case)\n",
    "            df_stats = pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_r'])\n",
    "            print(\"Train\", (p,r,f))\n",
    "            p,r,f,_ = eval_clf(blackbox_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=['baseline_e']))\n",
    "            print(\"Test\", (p,r,f))\n",
    "\n",
    "\n",
    "        print(\"Evaluating random strategy..\")\n",
    "        for nb_stolen in [1,10,100,250,500,1000,2500,5000,10000,25000,50000]:\n",
    "            if f'q_{nb_stolen}_e' in df_stats.index.tolist():\n",
    "                print(f\"Already evaluated {nb_stolen} queries - skipping\")\n",
    "                if nb_stolen > texts.shape[0]:\n",
    "                    # fully evaluated\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            print(f\"Training with {nb_stolen} queries to black box\")\n",
    "            knockoff = KnockoffNets(classifier = blackbox_classifier, batch_size_fit=32, batch_size_query=32, nb_stolen=nb_stolen, sampling_strategy=setting)\n",
    "            np.random.seed(23435432)\n",
    "            thieved_classifier = SpacyClassifier(model = spacy.load(\"en_core_web_sm\"), target_classes=target_class_dict.get(use_case))\n",
    "            knockoff.extract(x = texts, y=action_ids, thieved_classifier=thieved_classifier)\n",
    "\n",
    "            print(\"Evaluating on train/test set\")\n",
    "            p,r,f,_ = eval_clf(thieved_classifier, train_eval_texts, train_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'train']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_r']))\n",
    "            print(\"Train\", (p,r,f))\n",
    "            p,r,f,_ = eval_clf(thieved_classifier, test_eval_texts, test_eval_labels, use_case)\n",
    "            df_stats = df_stats.append(pd.DataFrame(data=np.array([p,r,f,'test']).reshape((1,4)), columns=['precision', 'recall', 'fscore', 'set'], index=[f'q_{nb_stolen}_e']))\n",
    "            print(\"Test\", (p,r,f))\n",
    "\n",
    "            print(\"Saving classifier\")\n",
    "            thieved_classifier.save(f'stolen-models-wex/{use_case}/{setting}_{nb_stolen}_queries/')\n",
    "            df_stats.to_csv(f'eval/{use_case}/wex_{setting}_res.csv')\n",
    "\n",
    "            if nb_stolen > texts.shape[0]:\n",
    "                print(\"Evaluated max query size - Stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
